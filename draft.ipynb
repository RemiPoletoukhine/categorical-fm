{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9TX2TmmsvQ7"
   },
   "source": [
    "# Variational Flow Matching for Graph Generation\n",
    "\n",
    "### by Floor Eijkelboom et al. (2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gdIbKlAsvQ8"
   },
   "source": [
    "Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "jrKavdz_svQ9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import glob\n",
    "import yaml\n",
    "import torch\n",
    "import random\n",
    "import einops\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torchdiffeq import odeint\n",
    "from torch.nn import functional as F\n",
    "from torch_geometric.data import Dataset, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_dense_adj, to_dense_batch, remove_self_loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We directly follow Eijkelboom et al. by adopting the implementation by Vignac et al. (2023), from **DiGress: Discrete Denoising diffusion for graph generation** by Vignac et al. (2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transformer_model import GraphTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlaceHolder:\n",
    "    def __init__(self, X, E, y):\n",
    "        self.X = X\n",
    "        self.E = E\n",
    "        self.y = y\n",
    "\n",
    "    def type_as(self, x: torch.Tensor):\n",
    "        \"\"\" Changes the device and dtype of X, E, y. \"\"\"\n",
    "        self.X = self.X.type_as(x)\n",
    "        self.E = self.E.type_as(x)\n",
    "        self.y = self.y.type_as(x)\n",
    "        return self\n",
    "\n",
    "    def mask(self, node_mask, collapse=False):\n",
    "        x_mask = node_mask.unsqueeze(-1)          # bs, n, 1\n",
    "        e_mask1 = x_mask.unsqueeze(2)             # bs, n, 1, 1\n",
    "        e_mask2 = x_mask.unsqueeze(1)             # bs, 1, n, 1\n",
    "\n",
    "        if collapse:\n",
    "            self.X = torch.argmax(self.X, dim=-1)\n",
    "            self.E = torch.argmax(self.E, dim=-1)\n",
    "\n",
    "            self.X[node_mask == 0] = - 1\n",
    "            self.E[(e_mask1 * e_mask2).squeeze(-1) == 0] = - 1\n",
    "        else:\n",
    "            self.X = self.X * x_mask\n",
    "            self.E = self.E * e_mask1 * e_mask2\n",
    "            assert torch.allclose(self.E, torch.transpose(self.E, 1, 2))\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/m852bq5j7gd84y0trm3pm2yr0000gn/T/ipykernel_27570/3168857350.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_data = torch.load(\"qm9/train_data_processed.pt\")\n",
      "/var/folders/g0/m852bq5j7gd84y0trm3pm2yr0000gn/T/ipykernel_27570/3168857350.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  val_data = torch.load(\"qm9/val_data_processed.pt\")\n"
     ]
    }
   ],
   "source": [
    "class QM9GraphDataset(Dataset):\n",
    "    def __init__(self, data, nodes_classes=5, edge_classes=4):\n",
    "        self.data = data\n",
    "        self.nodes_classes = nodes_classes\n",
    "        self.edge_classes = edge_classes\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data['node_idx_array'])  # Number of graphs\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get node and edge ranges for the idx-th molecule\n",
    "        node_start, node_end = self.data['node_idx_array'][idx]\n",
    "        edge_start, edge_end = self.data['edge_idx_array'][idx]\n",
    "\n",
    "        # Extract node and edge information\n",
    "        atom_types = self.data['atom_types'][node_start:node_end]  # Shape: [num_nodes, nodes_classes]\n",
    "        bond_idxs = self.data['bond_idxs'][edge_start:edge_end]    # Shape: [num_edges, 2]\n",
    "        bond_types = self.data['bond_types'][edge_start:edge_end].to(torch.long)  # Shape: [num_edges]\n",
    "\n",
    "        num_nodes = atom_types.shape[0]\n",
    "\n",
    "        # Initialize the node feature tensor (one-hot encoded node types)\n",
    "        node_labels = torch.argmax(atom_types.to(torch.float), dim=1)  # Get the node class labels\n",
    "        node_features = F.one_hot(node_labels, num_classes=self.nodes_classes)  # Shape: [num_nodes, nodes_classes]\n",
    "\n",
    "        # Initialize edge feature tensor\n",
    "        edge_class_matrix = torch.full((num_nodes, num_nodes), self.edge_classes - 1, dtype=torch.long)\n",
    "        for (src, dst), bond_type in zip(bond_idxs, bond_types):\n",
    "            edge_class_matrix[src, dst] = bond_type\n",
    "            edge_class_matrix[dst, src] = bond_type  # Ensure symmetry by assigning both directions\n",
    "\n",
    "        # Check for symmetry\n",
    "        assert torch.equal(edge_class_matrix, edge_class_matrix.T), \"edge_class_matrix is not symmetric\"\n",
    "        \n",
    "        edge_features = F.one_hot(edge_class_matrix, num_classes=self.edge_classes)  # Shape: [num_nodes, num_nodes, edge_classes]\n",
    "\n",
    "        # Create the PyTorch Geometric Data object (graph)\n",
    "        edge_index = torch.tensor(bond_idxs).T  # Shape: [2, num_edges]\n",
    "        \n",
    "        # Flatten edge feature matrix for each edge: [num_edges, edge_classes]\n",
    "        edge_attr = edge_features[edge_index[0], edge_index[1]]  # Shape: [num_edges, edge_classes]\n",
    "        \n",
    "        data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr)\n",
    "        return data\n",
    "    \n",
    "def create_dataloader(data, batch_size=32, nodes_classes=5, edge_classes=4):\n",
    "    # Create the dataset\n",
    "    dataset = QM9GraphDataset(data, nodes_classes, edge_classes)\n",
    "\n",
    "    # Create the DataLoader (PyTorch Geometric handles variable graph sizes)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "# Load your processed data\n",
    "train_data = torch.load(\"qm9/train_data_processed.pt\")\n",
    "val_data = torch.load(\"qm9/val_data_processed.pt\")\n",
    "\n",
    "# Create the DataLoader\n",
    "batch_size = 1\n",
    "train_dataloader = create_dataloader(train_data, batch_size=batch_size)\n",
    "val_dataloader = create_dataloader(val_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_no_edge(E):\n",
    "    assert len(E.shape) == 4, \"Expected shape [batch, nodes, nodes, edge_classes]\"\n",
    "    if E.shape[-1] == 0:\n",
    "        return E\n",
    "    \n",
    "    # Find locations where no edge is present in any class\n",
    "    no_edge = torch.sum(E, dim=3) == 0  # Shape: [batch, nodes, nodes]\n",
    "\n",
    "    # Set absence indicator (channel 0) at no-edge locations symmetrically\n",
    "    E[:, :, :, 0][no_edge] = 1\n",
    "    E[:, :, :, 0] = torch.max(E[:, :, :, 0], E[:, :, :, 0].transpose(1, 2))  # Make channel 0 symmetric\n",
    "    \n",
    "    # Copy all channels symmetrically for each [i, j] and [j, i] pair\n",
    "    for k in range(E.shape[-1]):\n",
    "        E[:, :, :, k] = torch.max(E[:, :, :, k], E[:, :, :, k].transpose(1, 2))\n",
    "\n",
    "    # Set diagonal elements to zero for all channels\n",
    "    diag = torch.eye(E.shape[1], dtype=torch.bool).unsqueeze(0).expand(E.shape[0], -1, -1)\n",
    "    E[diag] = 0\n",
    "    \n",
    "    # Ensure final symmetry in all channels\n",
    "    assert torch.allclose(E, E.transpose(1, 2)), \"encode_no_edge produced a non-symmetric tensor\"\n",
    "    return E\n",
    "\n",
    "\n",
    "def to_dense(x, edge_index, edge_attr, batch):\n",
    "    X, node_mask = to_dense_batch(x=x, batch=batch)\n",
    "    node_mask = node_mask.float()\n",
    "    edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)\n",
    "    max_num_nodes = X.size(1)\n",
    "    E = to_dense_adj(edge_index=edge_index, batch=batch, edge_attr=edge_attr, max_num_nodes=max_num_nodes)\n",
    "    E = encode_no_edge(E)\n",
    "\n",
    "    return PlaceHolder(X=X, E=E, y=None), node_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from Davis et al. (2024) Fisher Flow Matching, https://github.com/olsdavis/fisher-flow\n",
    "\n",
    "def timestep_embedding(timesteps, dim, max_period=10000):\n",
    "    \"\"\"\n",
    "    Create sinusoidal timestep embeddings.\n",
    "\n",
    "    :param timesteps: a 1-D Tensor of N indices, one per batch element.\n",
    "                      These may be fractional.\n",
    "    :param dim: the dimension of the output.\n",
    "    :param max_period: controls the minimum frequency of the embeddings.\n",
    "    :return: an [N x dim] Tensor of positional embeddings.\n",
    "    \"\"\"\n",
    "    half = dim // 2\n",
    "    freqs = torch.exp(\n",
    "        -math.log(max_period)\n",
    "        * torch.arange(start=0, end=half, dtype=torch.float32)\n",
    "        / half\n",
    "    ).to(device=timesteps.device)\n",
    "    args = timesteps[:, None].float() * freqs[None]\n",
    "    embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
    "    if dim % 2:\n",
    "        embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gaussian(size):\n",
    "    x = torch.randn(size)\n",
    "    return x\n",
    "\n",
    "def sample_feature_noise(X_size, E_size, y_size, node_mask):\n",
    "    \"\"\"Standard normal noise for all features.\n",
    "        Output size: X.size(), E.size(), y.size() \"\"\"\n",
    "    # TODO: How to change this for the multi-gpu case?\n",
    "    epsX = sample_gaussian(X_size)\n",
    "    epsE = sample_gaussian(E_size)\n",
    "    epsy = sample_gaussian(y_size)\n",
    "\n",
    "    float_mask = node_mask.float()\n",
    "    epsX = epsX.type_as(float_mask)\n",
    "    epsE = epsE.type_as(float_mask)\n",
    "    epsy = epsy.type_as(float_mask)\n",
    "\n",
    "    # Get upper triangular part of edge noise, without main diagonal\n",
    "    upper_triangular_mask = torch.zeros_like(epsE)\n",
    "    indices = torch.triu_indices(row=epsE.size(1), col=epsE.size(2), offset=1)\n",
    "    upper_triangular_mask[:, indices[0], indices[1], :] = 1\n",
    "\n",
    "    epsE = epsE * upper_triangular_mask\n",
    "    epsE = (epsE + torch.transpose(epsE, 1, 2))\n",
    "\n",
    "    assert (epsE == torch.transpose(epsE, 1, 2)).all()\n",
    "\n",
    "    return PlaceHolder(X=epsX, E=epsE, y=epsy).mask(node_mask)\n",
    "\n",
    "\n",
    "def sample_normal(mu_X, mu_E, mu_y, sigma, node_mask):\n",
    "    \"\"\"Samples from a Normal distribution.\"\"\"\n",
    "    # TODO: change for multi-gpu case\n",
    "    eps = sample_feature_noise(mu_X.size(), mu_E.size(), mu_y.size(), node_mask).type_as(mu_X)\n",
    "    X = mu_X + sigma * eps.X\n",
    "    E = mu_E + sigma.unsqueeze(1) * eps.E\n",
    "    y = mu_y + sigma.squeeze(1) * eps.y\n",
    "    return PlaceHolder(X=X, E=E, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRaqJi-RsvRA"
   },
   "source": [
    "### CatFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "k-IjtwwmsvRA"
   },
   "outputs": [],
   "source": [
    "class CatFlow(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: dict,\n",
    "        device: torch.device,\n",
    "        eps: float = 1e-6,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Constructor of the CatFlow model.\n",
    "\n",
    "        Args:\n",
    "            backbone_model (Backbone): Backbone model to extract features. In the case of our experiments, we use a graph transformer network.\n",
    "            batch_size (int): Batch size. Default value is 32.\n",
    "            num_nodes (int): Number of nodes. Default value is 10.\n",
    "            num_classes (int): Number of classes. Default value is 10.\n",
    "            eps (float): Epsilon value to avoid numerical instability. Default value is 1e-6.\n",
    "        \"\"\"\n",
    "        super(CatFlow, self).__init__()\n",
    "        self.backbone_model = GraphTransformer(\n",
    "            n_layers=config['n_layers'],\n",
    "            input_dims=config['input_dims'],\n",
    "            hidden_mlp_dims=config['hidden_mlp_dims'],\n",
    "            hidden_dims=config['hidden_dims'],\n",
    "            output_dims=config['output_dims'],\n",
    "        ).to(device)\n",
    "        self.batch_size = config['batch_size']\n",
    "        self.num_classes_nodes = config['input_dims']['X']\n",
    "        self.num_classes_edges = config['input_dims']['E']\n",
    "        self.eps = eps\n",
    "\n",
    "    def sample_time(self, lambd: torch.tensor = torch.tensor([1.0])) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Function to sample the time step for the CatFlow model.\n",
    "\n",
    "        Args:\n",
    "            lambd (torch.tensor): Rate parameter of the exponential distribution. Default value is 1.0.\n",
    "\n",
    "        Returns:\n",
    "            torch.tensor: Time step. Shape: (batch_size,).\n",
    "        \"\"\"\n",
    "        # As in Dirichlet Flow Matching, we sample the time step from Exp(1)\n",
    "        return torch.distributions.exponential.Exponential(lambd).sample().expand(self.batch_size)\n",
    "\n",
    "    def sample_noise(self, kind, num_nodes) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Function to sample the noise for the CatFlow model.\n",
    "        \n",
    "        Args:\n",
    "            kind (str): Type of noise to sample. Options: 'node' or 'edge'.\n",
    "\n",
    "        Returns:\n",
    "            torch.tensor: Noise. Shape: (batch_size, num_nodes + (num_nodes - 1)**2, num_classes + 1).\n",
    "        \"\"\"\n",
    "        # Judging by the page 7 of the paper: the noise is not constrained to the simplex; so we can sample from a normal distribution\n",
    "        # TODO: after figuring out the dimensions, use the proper forward pass\n",
    "        # return torch.randn(self.batch_size, self.num_nodes + (self.num_nodes - 1)**2, self.num_classes + 1)\n",
    "        if kind == 'node':\n",
    "            return torch.randn(self.batch_size, num_nodes, self.num_classes_nodes)\n",
    "        elif kind == 'edge':\n",
    "            return torch.randn(self.batch_size, num_nodes, num_nodes, self.num_classes_edges)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid noise type: {kind}\")\n",
    "    \n",
    "    \n",
    "    def forward(self, t: torch.tensor, x: torch.tensor, e: torch.tensor, node_mask: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the backbone model.\n",
    "\n",
    "        Args:\n",
    "            t (torch.tensor): Time step. Shape: (batch_size,).\n",
    "            x (torch.tensor): Node noise. Shape: (batch_size, num_nodes, num_classes_nodes).\n",
    "            e (torch.tensor): Edge noise. Shape: (batch_size, num_nodes, num_nodes, num_classes_edges).\n",
    "            \n",
    "\n",
    "        Returns:\n",
    "            torch.tensor: Parameters of the variational distribution. Shape: (batch_size, num_nodes + (num_nodes - 1)^2, num_classes + 1).\n",
    "        \"\"\"\n",
    "        # embed the timestep using the sinusoidal positional encoding\n",
    "        t_embedded_nodes = timestep_embedding(t, dim=x.shape[-1]) # Shape: (batch_size, num_classes_nodes)\n",
    "        t_embedded_edges = timestep_embedding(t, dim=e.shape[-1]) # Shape: (batch_size, num_classes_edges)\n",
    "        # add time embedding to the input across the class feature dimension\n",
    "        x += einops.rearrange(t_embedded_nodes, 'b c -> b 1 c')\n",
    "        e += einops.rearrange(t_embedded_edges, 'b c -> b 1 1 c')\n",
    "\n",
    "        return self.backbone_model(\n",
    "            X=x,\n",
    "            E=e,\n",
    "            # dummy y\n",
    "            y=torch.ones(self.batch_size, 1).to(device),\n",
    "            node_mask=node_mask,\n",
    "        )\n",
    "\n",
    "\n",
    "    def vector_field(self, t: torch.tensor, x: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Function that returns the vector field of the CatFlow model for a given timestamp.\n",
    "\n",
    "        Args:\n",
    "            t (torch.tensor): Time step. Shape: (batch_size, 1).\n",
    "            x (torch.tensor): Input noise. Shape: (batch_size, num_nodes + (num_nodes - 1)**2, num_classes + 1).\n",
    "\n",
    "        Returns:\n",
    "            torch.tensor: Vector field. Shape: (batch_size, num_nodes + (num_nodes - 1)**2, num_classes + 1).\n",
    "        \"\"\"\n",
    "\n",
    "        return (self.backbone_model(t, x) - x) / (1 - t)\n",
    "\n",
    "    def sampling(self, x: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Function to sample a new instance following the learned vector field.\n",
    "\n",
    "        Args:\n",
    "            x (torch.tensor): Input noise. Shape: (batch_size, num_nodes + (num_nodes - 1)**2, num_classes + 1).\n",
    "\n",
    "        Returns:\n",
    "            torch.tensor: Sampled result.\n",
    "        \"\"\"\n",
    "        # Define the time points over which to solve the ODE\n",
    "        time_points = torch.linspace(0, 0.95, steps=20)  # Adjust steps as needed\n",
    "\n",
    "        # Run the ODE solver with fixed time points\n",
    "        return odeint(self.vector_field, x, time_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxZ0T2uRsvRA"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare config\n",
    "config = yaml.safe_load(open('configs/catflow.yaml', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "VEKZvAtbsvRA",
    "outputId": "2e00d3ed-4808-4e46-9e7b-f8f22d29abbb"
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "catflow = CatFlow(config=config, device=device).to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.AdamW(catflow.parameters(), lr=0.0002, weight_decay=1e-12)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# define the seed\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def train_epoch(model, optimizer, dataloader, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in dataloader:#tqdm(dataloader):\n",
    "        data = data.to(device)\n",
    "        # Get the dense representation of the graph\n",
    "        dense_data, node_mask = to_dense(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "        x_true, e_true = dense_data.X.to(device), dense_data.E.to(device)\n",
    "        node_mask = node_mask.to(device)\n",
    "        num_nodes = x_true.size(1)#.to(device)\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # CatFlow forward pass\n",
    "        # Step 1: Sample t ~ Exp(1), x ~ N(0, I), e ~ N(0, I)\n",
    "        t = model.sample_time().to(device)\n",
    "        x = model.sample_noise(kind='node', num_nodes=num_nodes).to(device)\n",
    "        e = model.sample_noise(kind='edge', num_nodes=num_nodes).to(device)\n",
    "        # Step 2: Forward pass of the graph transformer\n",
    "        inferred = model.forward(t=t, x=x, e=e, node_mask=node_mask)\n",
    "        # Step 3: Calculate the loss\n",
    "        loss = criterion(inferred.X, x_true.float()) + criterion(inferred.E, e_true.float())\n",
    "        # Step 4: Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def validate_epoch(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:#tqdm(dataloader):\n",
    "            data = data.to(device)\n",
    "            # Get the dense representation of the graph\n",
    "            dense_data, node_mask = to_dense(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "            x_true, e_true = dense_data.X.to(device), dense_data.E.to(device)\n",
    "            node_mask = node_mask.to(device)\n",
    "            num_nodes = x_true.size(1)\n",
    "            # CatFlow forward pass\n",
    "            # Step 1: Sample t ~ Exp(1), x ~ N(0, I), e ~ N(0, I)\n",
    "            t = model.sample_time().to(device)\n",
    "            x = model.sample_noise(kind='node', num_nodes=num_nodes).to(device)\n",
    "            e = model.sample_noise(kind='edge', num_nodes=num_nodes).to(device)\n",
    "            # Step 2: Forward pass of the graph transformer\n",
    "            inferred = model.forward(t=t, x=x, e=e, node_mask=node_mask)\n",
    "            # Step 3: Calculate the loss\n",
    "            loss = criterion(inferred.X, x_true.float()) + criterion(inferred.E, e_true.float())\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/m852bq5j7gd84y0trm3pm2yr0000gn/T/ipykernel_27570/3168857350.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_index = torch.tensor(bond_idxs).T  # Shape: [2, num_edges]\n"
     ]
    }
   ],
   "source": [
    "for i in train_dataloader:\n",
    "    trial_batch = i\n",
    "    break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000: Train loss: 1.8866, Validation loss: 1.4932\n",
      "Epoch 26/1000: Train loss: 0.7687, Validation loss: 0.7307\n",
      "Epoch 51/1000: Train loss: 0.6128, Validation loss: 0.6401\n",
      "Epoch 76/1000: Train loss: 0.5009, Validation loss: 0.5600\n",
      "Epoch 101/1000: Train loss: 0.4733, Validation loss: 0.4771\n",
      "Epoch 126/1000: Train loss: 0.4648, Validation loss: 0.4714\n",
      "Epoch 151/1000: Train loss: 0.4520, Validation loss: 0.4431\n",
      "Epoch 176/1000: Train loss: 0.4376, Validation loss: 0.4720\n",
      "Epoch 201/1000: Train loss: 0.4454, Validation loss: 0.4321\n",
      "Epoch 226/1000: Train loss: 0.4379, Validation loss: 0.4187\n",
      "Epoch 251/1000: Train loss: 0.4174, Validation loss: 0.4353\n",
      "Epoch 276/1000: Train loss: 0.4318, Validation loss: 0.4168\n",
      "Epoch 301/1000: Train loss: 0.4086, Validation loss: 0.4316\n",
      "Epoch 326/1000: Train loss: 0.4385, Validation loss: 0.4126\n",
      "Epoch 351/1000: Train loss: 0.4309, Validation loss: 0.4194\n",
      "Epoch 376/1000: Train loss: 0.4133, Validation loss: 0.4254\n",
      "Epoch 401/1000: Train loss: 0.4278, Validation loss: 0.4253\n",
      "Epoch 426/1000: Train loss: 0.4255, Validation loss: 0.4225\n",
      "Epoch 451/1000: Train loss: 0.4192, Validation loss: 0.4379\n",
      "Epoch 476/1000: Train loss: 0.4199, Validation loss: 0.4177\n",
      "Epoch 501/1000: Train loss: 0.4345, Validation loss: 0.4288\n",
      "Epoch 526/1000: Train loss: 0.4466, Validation loss: 0.4175\n",
      "Epoch 551/1000: Train loss: 0.4216, Validation loss: 0.4333\n",
      "Epoch 576/1000: Train loss: 0.4321, Validation loss: 0.4453\n",
      "Epoch 601/1000: Train loss: 0.4292, Validation loss: 0.4271\n",
      "Epoch 626/1000: Train loss: 0.4294, Validation loss: 0.4240\n",
      "Epoch 651/1000: Train loss: 0.4221, Validation loss: 0.4265\n",
      "Epoch 676/1000: Train loss: 0.4537, Validation loss: 0.4215\n",
      "Epoch 701/1000: Train loss: 0.4298, Validation loss: 0.4159\n",
      "Epoch 726/1000: Train loss: 0.4379, Validation loss: 0.4170\n",
      "Epoch 751/1000: Train loss: 0.4141, Validation loss: 0.4224\n",
      "Epoch 776/1000: Train loss: 0.4129, Validation loss: 0.4273\n",
      "Epoch 801/1000: Train loss: 0.4200, Validation loss: 0.4231\n",
      "Epoch 826/1000: Train loss: 0.4182, Validation loss: 0.4171\n",
      "Epoch 851/1000: Train loss: 0.4307, Validation loss: 0.4303\n",
      "Epoch 876/1000: Train loss: 0.4242, Validation loss: 0.4077\n",
      "Epoch 901/1000: Train loss: 0.4280, Validation loss: 0.4153\n",
      "Epoch 926/1000: Train loss: 0.4252, Validation loss: 0.4302\n",
      "Epoch 951/1000: Train loss: 0.4351, Validation loss: 0.4171\n",
      "Epoch 976/1000: Train loss: 0.4294, Validation loss: 0.4180\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(catflow, optimizer, DataLoader(trial_batch), device)\n",
    "    val_loss = validate_epoch(catflow, DataLoader(trial_batch), device)\n",
    "    if epoch % 25 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}: Train loss: {train_loss:.4f}, Validation loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "categorical_fm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
