{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9TX2TmmsvQ7"
   },
   "source": [
    "# Variational Flow Matching for Graph Generation\n",
    "\n",
    "### by Floor Eijkelboom et al. (2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gdIbKlAsvQ8"
   },
   "source": [
    "Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jrKavdz_svQ9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/remi/miniconda3/envs/categorical_fm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import dgl.function as fn\n",
    "import torch.optim as optim\n",
    "from torchdiffeq import odeint\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HQxshcvsvQ9"
   },
   "source": [
    "### Backbone Graph Transformer\n",
    "\n",
    "#### by Vijay Prakash Dwivedi, Xavier Bresson (2021)\n",
    "\n",
    "The code is taken from the official implementation [here](https://github.com/graphdeeplearning/graphtransformer?tab=readme-ov-file). We use the part for the task of *SBMs_node_classification*, as this exactly reflects our classification objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4ffEHRQsvQ-"
   },
   "source": [
    "Utils from *layers/graph_transformer_layer.py* and *train/metrics.py*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util functions\n",
    "\n",
    "\n",
    "def src_dot_dst(src_field, dst_field, out_field):\n",
    "    def func(edges):\n",
    "        return {\n",
    "            out_field: (edges.src[src_field] * edges.dst[dst_field]).sum(\n",
    "                -1, keepdim=True\n",
    "            )\n",
    "        }\n",
    "\n",
    "    return func\n",
    "\n",
    "\n",
    "def scaled_exp(field, scale_constant):\n",
    "    def func(edges):\n",
    "        # clamp for softmax numerical stability\n",
    "        return {field: torch.exp((edges.data[field] / scale_constant).clamp(-5, 5))}\n",
    "\n",
    "    return func\n",
    "\n",
    "\n",
    "def accuracy_SBM(scores, targets):\n",
    "    S = targets.cpu().numpy()\n",
    "    C = np.argmax(torch.nn.Softmax(dim=1)(scores).cpu().detach().numpy(), axis=1)\n",
    "    CM = confusion_matrix(S, C).astype(np.float32)\n",
    "    nb_classes = CM.shape[0]\n",
    "    targets = targets.cpu().detach().numpy()\n",
    "    nb_non_empty_classes = 0\n",
    "    pr_classes = np.zeros(nb_classes)\n",
    "    for r in range(nb_classes):\n",
    "        cluster = np.where(targets == r)[0]\n",
    "        if cluster.shape[0] != 0:\n",
    "            pr_classes[r] = CM[r, r] / float(cluster.shape[0])\n",
    "            if CM[r, r] > 0:\n",
    "                nb_non_empty_classes += 1\n",
    "        else:\n",
    "            pr_classes[r] = 0.0\n",
    "    acc = 100.0 * np.sum(pr_classes) / float(nb_classes)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "xE8ktIIfsvQ-"
   },
   "outputs": [],
   "source": [
    "# Single attention head\n",
    "\n",
    "\n",
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, num_heads, use_bias):\n",
    "        super().__init__()\n",
    "\n",
    "        self.out_dim = out_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        if use_bias:\n",
    "            self.Q = nn.Linear(in_dim, out_dim * num_heads, bias=True)\n",
    "            self.K = nn.Linear(in_dim, out_dim * num_heads, bias=True)\n",
    "            self.V = nn.Linear(in_dim, out_dim * num_heads, bias=True)\n",
    "        else:\n",
    "            self.Q = nn.Linear(in_dim, out_dim * num_heads, bias=False)\n",
    "            self.K = nn.Linear(in_dim, out_dim * num_heads, bias=False)\n",
    "            self.V = nn.Linear(in_dim, out_dim * num_heads, bias=False)\n",
    "\n",
    "    def propagate_attention(self, g):\n",
    "        # Compute attention score\n",
    "        g.apply_edges(src_dot_dst(\"K_h\", \"Q_h\", \"score\"))  # , edges)\n",
    "        g.apply_edges(scaled_exp(\"score\", np.sqrt(self.out_dim)))\n",
    "\n",
    "        # Send weighted values to target nodes\n",
    "        eids = g.edges()\n",
    "        g.send_and_recv(\n",
    "            eids, fn.src_mul_edge(\"V_h\", \"score\", \"V_h\"), fn.sum(\"V_h\", \"wV\")\n",
    "        )\n",
    "        g.send_and_recv(eids, fn.copy_edge(\"score\", \"score\"), fn.sum(\"score\", \"z\"))\n",
    "\n",
    "    def forward(self, g, h):\n",
    "\n",
    "        Q_h = self.Q(h)\n",
    "        K_h = self.K(h)\n",
    "        V_h = self.V(h)\n",
    "\n",
    "        # Reshaping into [num_nodes, num_heads, feat_dim] to\n",
    "        # get projections for multi-head attention\n",
    "        g.ndata[\"Q_h\"] = Q_h.view(-1, self.num_heads, self.out_dim)\n",
    "        g.ndata[\"K_h\"] = K_h.view(-1, self.num_heads, self.out_dim)\n",
    "        g.ndata[\"V_h\"] = V_h.view(-1, self.num_heads, self.out_dim)\n",
    "\n",
    "        self.propagate_attention(g)\n",
    "\n",
    "        head_out = g.ndata[\"wV\"] / g.ndata[\"z\"]\n",
    "\n",
    "        return head_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphTransformerLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Param:\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim,\n",
    "        out_dim,\n",
    "        num_heads,\n",
    "        dropout=0.0,\n",
    "        layer_norm=False,\n",
    "        batch_norm=True,\n",
    "        residual=True,\n",
    "        use_bias=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_dim\n",
    "        self.out_channels = out_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.residual = residual\n",
    "        self.layer_norm = layer_norm\n",
    "        self.batch_norm = batch_norm\n",
    "\n",
    "        self.attention = MultiHeadAttentionLayer(\n",
    "            in_dim, out_dim // num_heads, num_heads, use_bias\n",
    "        )\n",
    "\n",
    "        self.O = nn.Linear(out_dim, out_dim)\n",
    "\n",
    "        if self.layer_norm:\n",
    "            self.layer_norm1 = nn.LayerNorm(out_dim)\n",
    "\n",
    "        if self.batch_norm:\n",
    "            self.batch_norm1 = nn.BatchNorm1d(out_dim)\n",
    "\n",
    "        # FFN\n",
    "        self.FFN_layer1 = nn.Linear(out_dim, out_dim * 2)\n",
    "        self.FFN_layer2 = nn.Linear(out_dim * 2, out_dim)\n",
    "\n",
    "        if self.layer_norm:\n",
    "            self.layer_norm2 = nn.LayerNorm(out_dim)\n",
    "\n",
    "        if self.batch_norm:\n",
    "            self.batch_norm2 = nn.BatchNorm1d(out_dim)\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        h_in1 = h  # for first residual connection\n",
    "\n",
    "        # multi-head attention out\n",
    "        attn_out = self.attention(g, h)\n",
    "        h = attn_out.view(-1, self.out_channels)\n",
    "\n",
    "        h = F.dropout(h, self.dropout, training=self.training)\n",
    "\n",
    "        h = self.O(h)\n",
    "\n",
    "        if self.residual:\n",
    "            h = h_in1 + h  # residual connection\n",
    "\n",
    "        if self.layer_norm:\n",
    "            h = self.layer_norm1(h)\n",
    "\n",
    "        if self.batch_norm:\n",
    "            h = self.batch_norm1(h)\n",
    "\n",
    "        h_in2 = h  # for second residual connection\n",
    "\n",
    "        # FFN\n",
    "        h = self.FFN_layer1(h)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, self.dropout, training=self.training)\n",
    "        h = self.FFN_layer2(h)\n",
    "\n",
    "        if self.residual:\n",
    "            h = h_in2 + h  # residual connection\n",
    "\n",
    "        if self.layer_norm:\n",
    "            h = self.layer_norm2(h)\n",
    "\n",
    "        if self.batch_norm:\n",
    "            h = self.batch_norm2(h)\n",
    "\n",
    "        return h\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"{}(in_channels={}, out_channels={}, heads={}, residual={})\".format(\n",
    "            self.__class__.__name__,\n",
    "            self.in_channels,\n",
    "            self.out_channels,\n",
    "            self.num_heads,\n",
    "            self.residual,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcOGFDjbsvQ_"
   },
   "source": [
    "Contents of the file *layers/mlp_readout_layer.py*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "xyWrkal6svQ_"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    MLP Layer used after graph vector representation\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class MLPReadout(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, L=2):  # L=nb_hidden_layers\n",
    "        super().__init__()\n",
    "        list_FC_layers = [\n",
    "            nn.Linear(input_dim // 2**l, input_dim // 2 ** (l + 1), bias=True)\n",
    "            for l in range(L)\n",
    "        ]\n",
    "        list_FC_layers.append(nn.Linear(input_dim // 2**L, output_dim, bias=True))\n",
    "        self.FC_layers = nn.ModuleList(list_FC_layers)\n",
    "        self.L = L\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        for l in range(self.L):\n",
    "            y = self.FC_layers[l](y)\n",
    "            y = F.relu(y)\n",
    "        y = self.FC_layers[self.L](y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fL5fTo6zsvQ_"
   },
   "source": [
    "Contents of the file *nets/SBMs_node_classification/graph_transformer_net.py*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2fvLvBWfsvQ_"
   },
   "outputs": [],
   "source": [
    "class GraphTransformerNet(nn.Module):\n",
    "\n",
    "    def __init__(self, net_params):\n",
    "        super().__init__()\n",
    "\n",
    "        in_dim_node = net_params[\"in_dim\"]  # node_dim (feat is an integer)\n",
    "        hidden_dim = net_params[\"hidden_dim\"]\n",
    "        out_dim = net_params[\"out_dim\"]\n",
    "        n_classes = net_params[\"n_classes\"]\n",
    "        num_heads = net_params[\"n_heads\"]\n",
    "        in_feat_dropout = net_params[\"in_feat_dropout\"]\n",
    "        dropout = net_params[\"dropout\"]\n",
    "        n_layers = net_params[\"L\"]\n",
    "\n",
    "        self.readout = net_params[\"readout\"]\n",
    "        self.layer_norm = net_params[\"layer_norm\"]\n",
    "        self.batch_norm = net_params[\"batch_norm\"]\n",
    "        self.residual = net_params[\"residual\"]\n",
    "        self.dropout = dropout\n",
    "        self.n_classes = n_classes\n",
    "        self.device = net_params[\"device\"]\n",
    "        self.lap_pos_enc = net_params[\"lap_pos_enc\"]\n",
    "        self.wl_pos_enc = net_params[\"wl_pos_enc\"]\n",
    "        max_wl_role_index = 100\n",
    "\n",
    "        if self.lap_pos_enc:\n",
    "            pos_enc_dim = net_params[\"pos_enc_dim\"]\n",
    "            self.embedding_lap_pos_enc = nn.Linear(pos_enc_dim, hidden_dim)\n",
    "        if self.wl_pos_enc:\n",
    "            self.embedding_wl_pos_enc = nn.Embedding(max_wl_role_index, hidden_dim)\n",
    "\n",
    "        self.embedding_h = nn.Embedding(\n",
    "            in_dim_node, hidden_dim\n",
    "        )  # node feat is an integer\n",
    "\n",
    "        self.in_feat_dropout = nn.Dropout(in_feat_dropout)\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                GraphTransformerLayer(\n",
    "                    hidden_dim,\n",
    "                    hidden_dim,\n",
    "                    num_heads,\n",
    "                    dropout,\n",
    "                    self.layer_norm,\n",
    "                    self.batch_norm,\n",
    "                    self.residual,\n",
    "                )\n",
    "                for _ in range(n_layers - 1)\n",
    "            ]\n",
    "        )\n",
    "        self.layers.append(\n",
    "            GraphTransformerLayer(\n",
    "                hidden_dim,\n",
    "                out_dim,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                self.layer_norm,\n",
    "                self.batch_norm,\n",
    "                self.residual,\n",
    "            )\n",
    "        )\n",
    "        self.MLP_layer = MLPReadout(out_dim, n_classes)\n",
    "\n",
    "    def forward(self, g, h, e, h_lap_pos_enc=None, h_wl_pos_enc=None):\n",
    "\n",
    "        # input embedding\n",
    "        h = self.embedding_h(h)\n",
    "        if self.lap_pos_enc:\n",
    "            h_lap_pos_enc = self.embedding_lap_pos_enc(h_lap_pos_enc.float())\n",
    "            h = h + h_lap_pos_enc\n",
    "        if self.wl_pos_enc:\n",
    "            h_wl_pos_enc = self.embedding_wl_pos_enc(h_wl_pos_enc)\n",
    "            h = h + h_wl_pos_enc\n",
    "        h = self.in_feat_dropout(h)\n",
    "\n",
    "        # GraphTransformer Layers\n",
    "        for conv in self.layers:\n",
    "            h = conv(g, h)\n",
    "\n",
    "        # output\n",
    "        h_out = self.MLP_layer(h)\n",
    "\n",
    "        return h_out\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "\n",
    "        # calculating label weights for weighted loss computation\n",
    "        V = label.size(0)\n",
    "        label_count = torch.bincount(label)\n",
    "        label_count = label_count[label_count.nonzero()].squeeze()\n",
    "        cluster_sizes = torch.zeros(self.n_classes).long().to(self.device)\n",
    "        cluster_sizes[torch.unique(label)] = label_count\n",
    "        weight = (V - cluster_sizes).float() / V\n",
    "        weight *= (cluster_sizes > 0).float()\n",
    "\n",
    "        # weighted cross-entropy for unbalanced classes\n",
    "        criterion = nn.CrossEntropyLoss(weight=weight)\n",
    "        loss = criterion(pred, label)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NinZahzLsvQ_"
   },
   "source": [
    "Contents of the file *train/train_SBMs_node_classification.py*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3WW8HzEhsvQ_"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Utility functions for training one epoch\n",
    "    and evaluating one epoch\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def train_epoch(model, optimizer, device, data_loader, epoch):\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_train_acc = 0\n",
    "    for iter, (batch_graphs, batch_labels) in enumerate(data_loader):\n",
    "        batch_graphs = batch_graphs.to(device)\n",
    "        batch_x = batch_graphs.ndata[\"feat\"].to(device)  # num x feat\n",
    "        batch_e = batch_graphs.edata[\"feat\"].to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        try:\n",
    "            batch_lap_pos_enc = batch_graphs.ndata[\"lap_pos_enc\"].to(device)\n",
    "            sign_flip = torch.rand(batch_lap_pos_enc.size(1)).to(device)\n",
    "            sign_flip[sign_flip >= 0.5] = 1.0\n",
    "            sign_flip[sign_flip < 0.5] = -1.0\n",
    "            batch_lap_pos_enc = batch_lap_pos_enc * sign_flip.unsqueeze(0)\n",
    "        except:\n",
    "            batch_lap_pos_enc = None\n",
    "\n",
    "        try:\n",
    "            batch_wl_pos_enc = batch_graphs.ndata[\"wl_pos_enc\"].to(device)\n",
    "        except:\n",
    "            batch_wl_pos_enc = None\n",
    "\n",
    "        batch_scores = model.forward(\n",
    "            batch_graphs, batch_x, batch_e, batch_lap_pos_enc, batch_wl_pos_enc\n",
    "        )\n",
    "\n",
    "        loss = model.loss(batch_scores, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.detach().item()\n",
    "        epoch_train_acc += accuracy_SBM(batch_scores, batch_labels)\n",
    "    epoch_loss /= iter + 1\n",
    "    epoch_train_acc /= iter + 1\n",
    "\n",
    "    return epoch_loss, epoch_train_acc, optimizer\n",
    "\n",
    "\n",
    "def evaluate_network(model, device, data_loader, epoch):\n",
    "\n",
    "    model.eval()\n",
    "    epoch_test_loss = 0\n",
    "    epoch_test_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for iter, (batch_graphs, batch_labels) in enumerate(data_loader):\n",
    "            batch_graphs = batch_graphs.to(device)\n",
    "            batch_x = batch_graphs.ndata[\"feat\"].to(device)\n",
    "            batch_e = batch_graphs.edata[\"feat\"].to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            try:\n",
    "                batch_lap_pos_enc = batch_graphs.ndata[\"lap_pos_enc\"].to(device)\n",
    "            except:\n",
    "                batch_lap_pos_enc = None\n",
    "\n",
    "            try:\n",
    "                batch_wl_pos_enc = batch_graphs.ndata[\"wl_pos_enc\"].to(device)\n",
    "            except:\n",
    "                batch_wl_pos_enc = None\n",
    "\n",
    "            batch_scores = model.forward(\n",
    "                batch_graphs, batch_x, batch_e, batch_lap_pos_enc, batch_wl_pos_enc\n",
    "            )\n",
    "            loss = model.loss(batch_scores, batch_labels)\n",
    "            epoch_test_loss += loss.detach().item()\n",
    "            epoch_test_acc += accuracy_SBM(batch_scores, batch_labels)\n",
    "        epoch_test_loss /= iter + 1\n",
    "        epoch_test_acc /= iter + 1\n",
    "\n",
    "    return epoch_test_loss, epoch_test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzxVormisvRA"
   },
   "source": [
    "Contents of the file *main_SBMs_node_classification.py*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "O-ghRxRMsvRA"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    TRAINING CODE\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def train_val_pipeline(dataset, params, net_params, dirs):\n",
    "\n",
    "    start0 = time.time()\n",
    "    per_epoch_time = []\n",
    "\n",
    "    trainset, valset, testset = dataset.train, dataset.val, dataset.test\n",
    "\n",
    "    root_log_dir, root_ckpt_dir, write_file_name, write_config_file = dirs\n",
    "    device = net_params[\"device\"]\n",
    "\n",
    "    log_dir = os.path.join(root_log_dir, \"RUN_\" + str(0))\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    # setting seeds\n",
    "    random.seed(params[\"seed\"])\n",
    "    np.random.seed(params[\"seed\"])\n",
    "    torch.manual_seed(params[\"seed\"])\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.manual_seed(params[\"seed\"])\n",
    "\n",
    "    print(\"Training Graphs: \", len(trainset))\n",
    "    print(\"Validation Graphs: \", len(valset))\n",
    "    print(\"Test Graphs: \", len(testset))\n",
    "    print(\"Number of Classes: \", net_params[\"n_classes\"])\n",
    "\n",
    "    model = GraphTransformerNet(net_params)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), lr=params[\"init_lr\"], weight_decay=params[\"weight_decay\"]\n",
    "    )\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode=\"min\",\n",
    "        factor=params[\"lr_reduce_factor\"],\n",
    "        patience=params[\"lr_schedule_patience\"],\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    epoch_train_losses, epoch_val_losses = [], []\n",
    "    epoch_train_accs, epoch_val_accs = [], []\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        trainset,\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        shuffle=True,\n",
    "        collate_fn=dataset.collate,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        valset,\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        shuffle=False,\n",
    "        collate_fn=dataset.collate,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        testset,\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        shuffle=False,\n",
    "        collate_fn=dataset.collate,\n",
    "    )\n",
    "\n",
    "    # At any point you can hit Ctrl + C to break out of training early.\n",
    "    try:\n",
    "        with tqdm(range(params[\"epochs\"])) as t:\n",
    "            for epoch in t:\n",
    "                t.set_description(\"Epoch %d\" % epoch)\n",
    "                start = time.time()\n",
    "\n",
    "                epoch_train_loss, epoch_train_acc, optimizer = train_epoch(\n",
    "                    model, optimizer, device, train_loader, epoch\n",
    "                )\n",
    "\n",
    "                epoch_val_loss, epoch_val_acc = evaluate_network(\n",
    "                    model, device, val_loader, epoch\n",
    "                )\n",
    "                _, epoch_test_acc = evaluate_network(model, device, test_loader, epoch)\n",
    "\n",
    "                epoch_train_losses.append(epoch_train_loss)\n",
    "                epoch_val_losses.append(epoch_val_loss)\n",
    "                epoch_train_accs.append(epoch_train_acc)\n",
    "                epoch_val_accs.append(epoch_val_acc)\n",
    "\n",
    "                writer.add_scalar(\"train/_loss\", epoch_train_loss, epoch)\n",
    "                writer.add_scalar(\"val/_loss\", epoch_val_loss, epoch)\n",
    "                writer.add_scalar(\"train/_acc\", epoch_train_acc, epoch)\n",
    "                writer.add_scalar(\"val/_acc\", epoch_val_acc, epoch)\n",
    "                writer.add_scalar(\"test/_acc\", epoch_test_acc, epoch)\n",
    "                writer.add_scalar(\n",
    "                    \"learning_rate\", optimizer.param_groups[0][\"lr\"], epoch\n",
    "                )\n",
    "\n",
    "                t.set_postfix(\n",
    "                    time=time.time() - start,\n",
    "                    lr=optimizer.param_groups[0][\"lr\"],\n",
    "                    train_loss=epoch_train_loss,\n",
    "                    val_loss=epoch_val_loss,\n",
    "                    train_acc=epoch_train_acc,\n",
    "                    val_acc=epoch_val_acc,\n",
    "                    test_acc=epoch_test_acc,\n",
    "                )\n",
    "\n",
    "                per_epoch_time.append(time.time() - start)\n",
    "\n",
    "                # Saving checkpoint\n",
    "                ckpt_dir = os.path.join(root_ckpt_dir, \"RUN_\")\n",
    "                if not os.path.exists(ckpt_dir):\n",
    "                    os.makedirs(ckpt_dir)\n",
    "                torch.save(\n",
    "                    model.state_dict(),\n",
    "                    \"{}.pkl\".format(ckpt_dir + \"/epoch_\" + str(epoch)),\n",
    "                )\n",
    "\n",
    "                files = glob.glob(ckpt_dir + \"/*.pkl\")\n",
    "                for file in files:\n",
    "                    epoch_nb = file.split(\"_\")[-1]\n",
    "                    epoch_nb = int(epoch_nb.split(\".\")[0])\n",
    "                    if epoch_nb < epoch - 1:\n",
    "                        os.remove(file)\n",
    "\n",
    "                scheduler.step(epoch_val_loss)\n",
    "\n",
    "                if optimizer.param_groups[0][\"lr\"] < params[\"min_lr\"]:\n",
    "                    print(\"\\n!! LR SMALLER OR EQUAL TO MIN LR THRESHOLD.\")\n",
    "                    break\n",
    "\n",
    "                # Stop training after params['max_time'] hours\n",
    "                if time.time() - start0 > params[\"max_time\"] * 3600:\n",
    "                    print(\"-\" * 89)\n",
    "                    print(\n",
    "                        \"Max_time for training elapsed {:.2f} hours, so stopping\".format(\n",
    "                            params[\"max_time\"]\n",
    "                        )\n",
    "                    )\n",
    "                    break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"-\" * 89)\n",
    "        print(\"Exiting from training early because of KeyboardInterrupt\")\n",
    "\n",
    "    _, test_acc = evaluate_network(model, device, test_loader, epoch)\n",
    "    _, train_acc = evaluate_network(model, device, train_loader, epoch)\n",
    "    print(\"Test Accuracy: {:.4f}\".format(test_acc))\n",
    "    print(\"Train Accuracy: {:.4f}\".format(train_acc))\n",
    "    print(\"Convergence Time (Epochs): {:.4f}\".format(epoch))\n",
    "    print(\"TOTAL TIME TAKEN: {:.4f}s\".format(time.time() - start0))\n",
    "    print(\"AVG TIME PER EPOCH: {:.4f}s\".format(np.mean(per_epoch_time)))\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    \"\"\"\n",
    "        Write the results in out_dir/results folder\n",
    "    \"\"\"\n",
    "    with open(write_file_name + \".txt\", \"w\") as f:\n",
    "        f.write(\n",
    "            \"\"\"Dataset: {},\\nModel: {}\\n\\nparams={}\\n\\nnet_params={}\\n\\n{}\\n\\nTotal Parameters: {}\\n\\n\n",
    "    FINAL RESULTS\\nTEST ACCURACY: {:.4f}\\nTRAIN ACCURACY: {:.4f}\\n\\n\n",
    "    Convergence Time (Epochs): {:.4f}\\nTotal Time Taken: {:.4f} hrs\\nAverage Time Per Epoch: {:.4f} s\\n\\n\\n\"\"\".format(\n",
    "                \"Test\",\n",
    "                \"Test\",\n",
    "                params,\n",
    "                net_params,\n",
    "                model,\n",
    "                net_params[\"total_param\"],\n",
    "                test_acc,\n",
    "                train_acc,\n",
    "                epoch,\n",
    "                (time.time() - start0) / 3600,\n",
    "                np.mean(per_epoch_time),\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instead of taking the original implementation, we directly follow Eijkelboom et al. by adopting the implementation by Vignac et al. (2023), from **DiGress: Discrete Denoising diffusion for graph generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add softmax to the output layer\n",
    "from transformer_model import GraphTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from Davis et al. (2024) Fisher Flow Matching, https://github.com/olsdavis/fisher-flow\n",
    "def timestep_embedding(timesteps, dim, max_period=10000):\n",
    "    \"\"\"\n",
    "    Create sinusoidal timestep embeddings.\n",
    "\n",
    "    :param timesteps: a 1-D Tensor of N indices, one per batch element.\n",
    "                      These may be fractional.\n",
    "    :param dim: the dimension of the output.\n",
    "    :param max_period: controls the minimum frequency of the embeddings.\n",
    "    :return: an [N x dim] Tensor of positional embeddings.\n",
    "    \"\"\"\n",
    "    half = dim // 2\n",
    "    freqs = torch.exp(\n",
    "        -math.log(max_period)\n",
    "        * torch.arange(start=0, end=half, dtype=torch.float32)\n",
    "        / half\n",
    "    ).to(device=timesteps.device)\n",
    "    args = timesteps[:, None].float() * freqs[None]\n",
    "    embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
    "    if dim % 2:\n",
    "        embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fp5GzjPDsvRA"
   },
   "source": [
    "### Our definition of the Backbone for the CatFlow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "MNjEp94GsvRA"
   },
   "outputs": [],
   "source": [
    "# TODO: add +1 to the num_classes that denotes the absence of an edge\n",
    "\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Backbone, self).__init__()\n",
    "        # TODO: Figure out the proper model dictionary dimensions and add to the signature\n",
    "        self.batch_size = 10\n",
    "        self.num_nodes = 10\n",
    "        self.num_classes = 10\n",
    "\n",
    "        n_layers = 2\n",
    "        input_dims = {\"X\": 10, \"E\": 10, \"y\": 10}\n",
    "        hidden_mlp_dims = {\"X\": 10, \"E\": 10, \"y\": 10}\n",
    "        hidden_dims = {\n",
    "            \"dx\": 10,\n",
    "            \"de\": 10,\n",
    "            \"dy\": 10,\n",
    "            \"n_head\": 2,\n",
    "            \"dim_ffX\": 10,\n",
    "            \"dim_ffE\": 10,\n",
    "        }\n",
    "        output_dims = {\"X\": 10, \"E\": 10, \"y\": 10}\n",
    "\n",
    "        self.graph_transformer = GraphTransformer(\n",
    "            n_layers=n_layers,\n",
    "            input_dims=input_dims,\n",
    "            hidden_mlp_dims=hidden_mlp_dims,\n",
    "            hidden_dims=hidden_dims,\n",
    "            output_dims=output_dims,\n",
    "        )\n",
    "\n",
    "    def forward(self, t: torch.tensor, x: torch.tensor):\n",
    "        \"\"\"\n",
    "        Forward pass of the backbone model.\n",
    "\n",
    "        Args:\n",
    "            t (torch.tensor): Time step. Shape: (batch_size, num_nodes, 1).\n",
    "            x (torch.tensor): Input noise. Shape: (batch_size, num_nodes + (num_nodes - 1)^2, num_classes + 1). The second dimension corresponds to the nodes and edges of the graph, respectively.\n",
    "\n",
    "        Returns:\n",
    "            torch.tensor: Parameters of the variational distribution. Shape: (batch_size, num_nodes + (num_nodes - 1)^2, num_classes + 1).\n",
    "        \"\"\"\n",
    "        # embed the timestep using the sinusoidal positional encoding\n",
    "        print(t.shape)\n",
    "        t_embedded = timestep_embedding(t, dim=self.num_classes)\n",
    "        # add time embedding to the input\n",
    "        print(x.shape)\n",
    "        print(t_embedded.shape)\n",
    "        print(t_embedded[:, None, :].shape)\n",
    "        x += t_embedded[:, None, :]\n",
    "        # TODO: after figuring out the dimensions, use the proper forward pass\n",
    "        # return self.graph_transformer(X=x[:, :self.num_nodes, :], E=x[:, self.num_nodes:, :], y=torch.zeros(self.batch_size, self.num_classes + 1), node_mask=torch.ones(self.batch_size, self.num_nodes))\n",
    "        return self.graph_transformer(\n",
    "            X=x,\n",
    "            E=x,\n",
    "            y=torch.zeros(self.batch_size, self.num_classes),\n",
    "            node_mask=torch.ones(self.batch_size, self.num_nodes),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRaqJi-RsvRA"
   },
   "source": [
    "### CatFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "k-IjtwwmsvRA"
   },
   "outputs": [],
   "source": [
    "class CatFlow:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        backbone_model: Backbone,\n",
    "        batch_size: int = 10,\n",
    "        num_nodes: int = 10,\n",
    "        num_classes: int = 10,\n",
    "        eps: float = 1e-6,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Constructor of the CatFlow model.\n",
    "\n",
    "        Args:\n",
    "            backbone_model (Backbone): Backbone model to extract features. In the case of our experiments, we use a graph transformer network.\n",
    "            batch_size (int): Batch size. Default value is 32.\n",
    "            num_nodes (int): Number of nodes. Default value is 10.\n",
    "            num_classes (int): Number of classes. Default value is 10.\n",
    "            eps (float): Epsilon value to avoid numerical instability. Default value is 1e-6.\n",
    "        \"\"\"\n",
    "        self.backbone_model = backbone_model\n",
    "        self.batch_size = batch_size\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_classes = num_classes\n",
    "        self.eps = eps\n",
    "\n",
    "    def sample_time(self, lambd: torch.tensor = torch.tensor([1.0])) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Function to sample the time step for the CatFlow model.\n",
    "\n",
    "        Args:\n",
    "            lambd (torch.tensor): Rate parameter of the exponential distribution. Default value is 1.0.\n",
    "\n",
    "        Returns:\n",
    "            torch.tensor: Time step. Shape: (1,).\n",
    "        \"\"\"\n",
    "        # As in Dirichlet Flow Matching, we sample the time step from Exp(1)\n",
    "        return torch.distributions.exponential.Exponential(lambd).sample()\n",
    "\n",
    "    def sample_noise(self) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Function to sample the noise for the CatFlow model.\n",
    "\n",
    "        Returns:\n",
    "            torch.tensor: Noise. Shape: (batch_size, num_nodes + (num_nodes - 1)**2, num_classes + 1).\n",
    "        \"\"\"\n",
    "        # Judging by the page 7 of the paper: the noise is not constrained to the simplex; so we can sample from a normal distribution\n",
    "        # TODO: after figuring out the dimensions, use the proper forward pass\n",
    "        # return torch.randn(self.batch_size, self.num_nodes + (self.num_nodes - 1)**2, self.num_classes + 1)\n",
    "        return torch.randn(self.batch_size, self.num_nodes, self.num_classes)\n",
    "\n",
    "    def loss(self, theta_true: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Function to calculate the cross entropy loss of the CatFlow model.\n",
    "        Theta corresponds to the parameters of the variational distribution for the categorical case.\n",
    "\n",
    "        Args:\n",
    "            theta_true (torch.tensor): One-hot encoded true classes for the batch of samples. Shape: (batch_size, num_nodes + (num_nodes - 1)**2, num_classes + 1).\n",
    "\n",
    "        Returns:\n",
    "            torch.tensor: Cross entropy loss.\n",
    "        \"\"\"\n",
    "        # Sample time steps\n",
    "        t = self.sample_time()\n",
    "        # Sample noise\n",
    "        x = self.sample_noise()\n",
    "        # Forward pass of the backbone model\n",
    "        theta_pred = self.backbone_model(t, x)\n",
    "        # TODO: remove, just for testing\n",
    "        theta_pred = F.relu(theta_pred.X)\n",
    "        # Calculate cross entropy loss\n",
    "        return -torch.sum(theta_true * torch.log(theta_pred + self.eps))\n",
    "\n",
    "    def vector_field(self, t: torch.tensor, x: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Function that returns the vector field of the CatFlow model for a given timestamp.\n",
    "\n",
    "        Args:\n",
    "            t (torch.tensor): Time step. Shape: (batch_size, 1).\n",
    "            x (torch.tensor): Input noise. Shape: (batch_size, num_nodes + (num_nodes - 1)**2, num_classes + 1).\n",
    "\n",
    "        Returns:\n",
    "            torch.tensor: Vector field. Shape: (batch_size, num_nodes + (num_nodes - 1)**2, num_classes + 1).\n",
    "        \"\"\"\n",
    "\n",
    "        return (self.backbone_model(t, x) - x) / (1 - t)\n",
    "\n",
    "    def sampling(self, x: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Function to sample a new instance following the learned vector field.\n",
    "\n",
    "        Args:\n",
    "            x (torch.tensor): Input noise. Shape: (batch_size, num_nodes + (num_nodes - 1)**2, num_classes + 1).\n",
    "\n",
    "        Returns:\n",
    "            torch.tensor: Sampled result.\n",
    "        \"\"\"\n",
    "        # Define the time points over which to solve the ODE\n",
    "        time_points = torch.linspace(0, 0.95, steps=20)  # Adjust steps as needed\n",
    "\n",
    "        # Run the ODE solver with fixed time points\n",
    "        return odeint(self.vector_field, x, time_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check: a single forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch\n",
    "\n",
    "# Generate random indices for the one-hot encoding\n",
    "indices = torch.randint(0, 10, (10, 10))\n",
    "# Create a one-hot encoded tensor using scatter\n",
    "x = torch.zeros(10, 10, 10).scatter_(2, indices.unsqueeze(-1), 1)\n",
    "\n",
    "graph_transformer = Backbone()\n",
    "catflow = CatFlow(backbone_model=graph_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "torch.Size([10, 10, 10])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 1, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(372.9319, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catflow.loss(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxZ0T2uRsvRA"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "VEKZvAtbsvRA",
    "outputId": "2e00d3ed-4808-4e46-9e7b-f8f22d29abbb"
   },
   "outputs": [],
   "source": [
    "# TBD: implement the training loop for the CatFlow model"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "categorical_fm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
